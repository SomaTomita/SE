# System Design Concepts: Computer Architecture Basics

## Core Components

### Data Units

- **Bit**: Smallest data unit (0 or 1)
- **Byte**: 8 bits, represents single character/number
- **Scaling**: Kilobyte → Megabyte → Gigabyte → Terabyte

### Storage Components

### 1. **Disk Storage**

- Non-volatile (maintains data without power)
- Types: HDD, SSD
- Size: Hundreds of GB to multiple TB
- Speed comparison:
  - SSD: 500Mbps - 3500MBps
  - HDD: 80-160MBps

### 2. **RAM (Random Access Memory)**

- Primary active data holder
- Volatile (requires power)
- Size: Few GB to hundreds of GB
- Speed: >5000 Mb/s
- Stores:

  - Data structures
  - Variables
  - Runtime stack
  - Active application data

- #### Comparison Table: RAM vs Disk

| Feature      | RAM (Memory)                                    | Disk Storage (HDD / SSD)                        |
| ------------ | ----------------------------------------------- | ----------------------------------------------- |
| Type         | Volatile (data lost when power is off)          | Non-volatile (data persists without power)      |
| Main Usage   | Temporary data for active processing            | Long-term storage for files and programs        |
| Access Speed | Very fast (>5000 Mb/s)                          | Slower (SSD: 500MBps–3500MBps, HDD: 80–160MBps) |
| Capacity     | Few GB to hundreds of GB                        | Hundreds of GB to multiple TB                   |
| Example Uses | Storing variables, buffers, runtime application | Storing OS, documents, videos, installed apps   |

##### Practical Example: Opening and Editing a File

1. A file is **stored on disk** (SSD or HDD).
2. When opened, it is **loaded into RAM** for fast processing.
3. While editing (e.g., in Excel or Word), all changes happen in **RAM**.
4. Once saved, the updated file is written back to **disk**.
5. If power is lost before saving, RAM data is **lost** but disk data remains unchanged.

### 3. **Cache**

- Smaller than RAM (measured in MB)
- Fastest access times
- Hierarchy: L1 → L2 → L3
- Purpose: Reduce average data access time

##### Practical Example: How Cache Works

1. When the CPU or application needs data, it first checks the **cache**.
2. If the data is found (a _cache hit_), it is returned immediately, saving time.
3. If not (a _cache miss_), the system fetches it from a slower source (like RAM or disk), stores it in cache, and then returns it.
4. Frequently accessed data stays in cache to speed up future access.

##### Cache Management

- Caches are usually managed automatically using policies like **LRU (Least Recently Used)**.
- Each cached item may have a **TTL (Time To Live)**, after which it expires.
- Applications may allow **manual cache clearing** to remove outdated or corrupted data.
- To ensure updated data is retrieved, **cache-busting** techniques (like appending version numbers to URLs) are used in web development.

- Cache is stored in various locations, including inside the CPU, RAM, disk, and browser storage, depending on the situation in which it is used.

  | Cache Type            | Storage Location                 | Examples / Usage                                                                  |
  | --------------------- | -------------------------------- | --------------------------------------------------------------------------------- |
  | **CPU Cache**         | **Inside the CPU (L1/L2/L3)**    | Temporarily stores instructions and data for ultra-fast access (nanoseconds).     |
  | **Memory Cache**      | **RAM**                          | Caches recently accessed files and apps for quick reopening.                      |
  | **Disk Cache**        | **SSD/HDD cache area**           | Optimizes read/write operations; managed by the OS.                               |
  | **Browser Cache**     | **Local storage or disk**        | Stores images, JS, CSS for faster website loading.                                |
  | **Application Cache** | **RAM or disk**                  | Game assets, media files like Spotify songs cached for faster access.             |
  | **OS-Level Cache**    | **RAM or swap area**             | Frequently used libraries and files preloaded to speed up operations.             |
  | **Server/DB Cache**   | **RAM (e.g., Redis, Memcached)** | Caches DB query results, sessions, and request data for high-performance systems. |

###### Use Cases: Redis and Memcached

- **Redis** and **Memcached** are **in-memory key-value stores** often used as external caches.
- Common use cases:
  - **Web applications**: Store session data, user preferences, or temporary results.
  - **Database query caching**: Reduce load by storing results of frequent queries.
  - **Rate limiting**: Temporarily store request counts per user/IP.

Both provide **ultra-fast read/write** access and are often used in high-performance, distributed systems.

### Processing Components

1. **CPU**

   - Main processor ("brain")
   - Functions:
     - Fetches instructions
     - Decodes instructions
     - Executes instructions
   - Works with compiled machine code

2. **Motherboard**
   - Connects all components
   - Provides data pathways between components

## CPU and Memory Mechanisms

### Basic Operation Flow

1. **Program Execution Cycle**

   - Fetch: CPU gets instruction from memory
   - Decode: CPU understands what to do
   - Execute: CPU performs the operation
   - Store: CPU saves results if needed

2. **Key Components Inside CPU**
   - Control Unit: Manages operations
   - Arithmetic Logic Unit (ALU): Does calculations
   - Registers: Small, fast storage areas
   - Program Counter: Tracks next instruction
   - Clock Generator: Controls timing

### Memory Interaction

1. **Memory Access**

   - Memory divided into addresses
   - Each address holds data or instructions
   - CPU reads/writes through memory bus
   - Data flows between CPU and memory

2. **Example: Simple Addition**
   ```
   Address  |  Content
   100     |    10
   101     |    20
   102     |    Result
   ```
   - Read first number from address 100
   - Read second number from address 101
   - Add numbers in ALU
   - Store result in address 102

### Processing Speed and Efficiency

1. **Clock Frequency**

   - Measured in Hertz (Hz)
   - Modern CPUs: Several GHz
   - One cycle = one basic operation
   - Higher frequency = faster processing

2. **Performance Improvements**
   - Increased bit width (32-bit → 64-bit)
   - Multiple cores (parallel processing)
   - Larger cache memory
   - Advanced instruction sets

### Memory Hierarchy

1. **Registers**

   - Fastest access (< 1ns)
   - Very small capacity
   - Inside CPU
   - Holds current operations

2. **Cache Memory**
   - L1: Fastest cache
   - L2: Larger but slower
   - L3: Largest but slowest cache
   - Bridges CPU-RAM speed gap

## Summary

The CPU and memory system works through a coordinated dance of components. The CPU fetches instructions from memory, processes them through its internal components (Control Unit and ALU), and stores results back in memory. This process is synchronized by the clock signal, which sets the pace for all operations. Modern improvements focus on parallel processing (multiple cores) rather than just increasing clock speed, as well as efficient memory hierarchy management through various cache levels.

Key points to remember:

- CPU operates in a fetch-decode-execute cycle
- Memory is organized by addresses
- Clock frequency determines basic operation speed
- Multiple cores allow parallel processing
- Memory hierarchy optimizes data access speed
